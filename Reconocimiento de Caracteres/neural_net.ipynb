{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0419b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports principales\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "# Optuna se usará en la celda de AutoML; aquí no lo importamos aún para evitar fallos si no está instalado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef4d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración global y rutas\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DATASET_ROOT = Path(\"Reconocimiento de Caracteres/datasets/synthetic\")\n",
    "BATCH_SIZE = 16\n",
    "VAL_FRAC = 0.3\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print('Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c832d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del Dataset (compatible con las carpetas images/, masks/, masks_ignore/)\n",
    "class SyntheticGlyphsDataset(Dataset):\n",
    "    def __init__(self, root: Path, files: List[str]):\n",
    "        self.root = Path(root)\n",
    "        self.images_dir = self.root / 'images'\n",
    "        self.masks_dir = self.root / 'masks'\n",
    "        self.masks_ignore_dir = self.root / 'masks_ignore'\n",
    "        self.files = list(files)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        fname = self.files[idx]\n",
    "        img = Image.open(self.images_dir / fname).convert('RGB')\n",
    "        mask = Image.open(self.masks_dir / fname).convert('L')\n",
    "        ignore_path = self.masks_ignore_dir / fname\n",
    "        if ignore_path.exists():\n",
    "            ignore = Image.open(ignore_path).convert('L')\n",
    "        else:\n",
    "            ignore = Image.new('L', mask.size, 0)\n",
    "\n",
    "        img_t = TF.to_tensor(img)\n",
    "        mask_t = TF.to_tensor(mask)\n",
    "        ignore_t = TF.to_tensor(ignore)\n",
    "\n",
    "        mask_bin = (mask_t > 0.0).float()\n",
    "        ignore_bin = (ignore_t > 0.0).float()\n",
    "\n",
    "        return {'image': img_t, 'mask': mask_bin, 'ignore': ignore_bin, 'file': fname}\n",
    "\n",
    "def build_file_list(root: Path) -> List[str]:\n",
    "    images_dir = root / 'images'\n",
    "    if not images_dir.exists():\n",
    "        return []\n",
    "    return [p.name for p in sorted(images_dir.glob('*.png'))]\n",
    "\n",
    "def split_files(files: List[str], val_frac: float = 0.1, seed: int | None = 42) -> Tuple[List[str], List[str]]:\n",
    "    rng = random.Random(seed)\n",
    "    files_shuffled = list(files)\n",
    "    rng.shuffle(files_shuffled)\n",
    "    n = len(files_shuffled)\n",
    "    n_val = int(n * val_frac)\n",
    "    val = files_shuffled[:n_val]\n",
    "    train = files_shuffled[n_val:]\n",
    "    return train, val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddecc3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción de DataLoaders (train / val)\n",
    "files = build_file_list(DATASET_ROOT)\n",
    "print('Found files:', len(files))\n",
    "train_files, val_files = split_files(files, val_frac=VAL_FRAC, seed=SEED)\n",
    "print(f'Train: {len(train_files)} files, Val: {len(val_files)} files')\n",
    "\n",
    "train_ds = SyntheticGlyphsDataset(DATASET_ROOT, train_files)\n",
    "val_ds = SyntheticGlyphsDataset(DATASET_ROOT, val_files)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print('Train batches:', len(train_loader), 'Val batches:', len(val_loader))\n",
    "# show example shapes if dataset non-empty\n",
    "if len(train_ds) > 0:\n",
    "    sample = train_ds[0]\n",
    "    print('Sample keys:', list(sample.keys()))\n",
    "    print('image shape', sample['image'].shape, 'mask shape', sample['mask'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e86a43",
   "metadata": {},
   "source": [
    "## AutoML / HPO — decisión metodológica\n",
    "\n",
    "Seleccionaremos Optuna con un pruner tipo ASHA (Successive Halving) porque permite detener trials de bajo rendimiento tempranamente y es sencillo de integrar.\n",
    "Se trabajará en dos fases: búsqueda proxy (imágenes 128×128, 5 epochs por trial) y reevaluación de los mejores candidatos en mayor fidelidad.\n",
    "La métrica objetivo será mIoU (Dice/IoU) calculada ignorando píxeles en `masks_ignore`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4012a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación completa de AutoML / HPO con Optuna + ASHA (incluyendo selección de arquitectura)\n",
    "# Instalar optuna si no está disponible: pip install optuna\n",
    "# Para visualizaciones: pip install plotly (si no está instalado)\n",
    "\n",
    "import time\n",
    "import math\n",
    "try:\n",
    "    import optuna\n",
    "    from optuna.pruners import SuccessiveHalvingPruner\n",
    "    import optuna.visualization as vis\n",
    "except Exception as e:\n",
    "    print('Optuna no disponible. Instalar con `pip install optuna plotly`.')\n",
    "    raise\n",
    "\n",
    "# Definimos modelos dentro del notebook para pruebas rápidas\n",
    "import torch.nn as nn\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self, in_ch=3, base=32):\n",
    "        super().__init__()\n",
    "        self.enc1 = DoubleConv(in_ch, base)\n",
    "        self.enc2 = DoubleConv(base, base*2)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.dec1 = DoubleConv(base*2, base)\n",
    "        self.outc = nn.Conv2d(base, 1, 1)\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        d = self.up(e2)\n",
    "        d = self.dec1(d)\n",
    "        return torch.sigmoid(self.outc(d))\n",
    "\n",
    "class SimpleFCN(nn.Module):\n",
    "    def __init__(self, in_ch=3, base=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = DoubleConv(in_ch, base)\n",
    "        self.conv2 = DoubleConv(base, base*2)\n",
    "        self.conv3 = DoubleConv(base*2, base*4)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        self.dec1 = DoubleConv(base*4, base*2)\n",
    "        self.dec2 = DoubleConv(base*2, base)\n",
    "        self.outc = nn.Conv2d(base, 1, 1)\n",
    "    def forward(self, x):\n",
    "        c1 = self.conv1(x)\n",
    "        p1 = self.pool(c1)\n",
    "        c2 = self.conv2(p1)\n",
    "        p2 = self.pool(c2)\n",
    "        c3 = self.conv3(p2)\n",
    "        u1 = self.up1(c3)\n",
    "        d1 = self.dec1(u1)\n",
    "        u2 = self.up2(d1)\n",
    "        d2 = self.dec2(u2)\n",
    "        return torch.sigmoid(self.outc(d2))\n",
    "\n",
    "# Métrica: IoU ignorando píxeles 'ignore'\n",
    "def iou_metric(pred, target, ignore_mask=None, eps=1e-7):\n",
    "    # pred, target: tensors (B,1,H,W)\n",
    "    pred_bin = (pred > 0.5).float()\n",
    "    target = target.float()\n",
    "    if ignore_mask is not None:\n",
    "        mask = (ignore_mask < 0.5).float()\n",
    "        pred_bin = pred_bin * mask\n",
    "        target = target * mask\n",
    "    inter = (pred_bin * target).sum(dim=[1,2,3])\n",
    "    union = (pred_bin + target - pred_bin * target).sum(dim=[1,2,3])\n",
    "    iou = ((inter + eps) / (union + eps)).mean().item()\n",
    "    return iou\n",
    "\n",
    "# Objective function for Optuna (ahora incluye selección de arquitectura)\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    # Seleccionar arquitectura\n",
    "    model_type = trial.suggest_categorical('model_type', ['unet', 'fcn'])\n",
    "    \n",
    "    # Hiperparámetros comunes\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-3, log=True)\n",
    "    base = trial.suggest_categorical('base', [16, 32, 48])\n",
    "    weight_decay = trial.suggest_float('wd', 0.0, 1e-4, log=True)\n",
    "    \n",
    "    # Construir modelo según tipo\n",
    "    if model_type == 'unet':\n",
    "        model = SimpleUNet(in_ch=3, base=base).to(DEVICE)\n",
    "    elif model_type == 'fcn':\n",
    "        model = SimpleFCN(in_ch=3, base=base).to(DEVICE)\n",
    "    \n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.BCELoss()\n",
    "\n",
    "    # Quick train loop (proxy): 5 epochs\n",
    "    n_epochs = 5\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            imgs = batch['image'].to(DEVICE)\n",
    "            masks = batch['mask'].to(DEVICE)\n",
    "            ignores = batch['ignore'].to(DEVICE)\n",
    "            pred = model(imgs)\n",
    "            loss = loss_fn(pred, masks)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        # Validation metric\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            ious = []\n",
    "            for vb in val_loader:\n",
    "                imgs = vb['image'].to(DEVICE)\n",
    "                masks = vb['mask'].to(DEVICE)\n",
    "                ignores = vb['ignore'].to(DEVICE)\n",
    "                pred = model(imgs)\n",
    "                ious.append(iou_metric(pred, masks, ignore_mask=ignores))\n",
    "            val_iou = float(np.mean(ious)) if ious else 0.0\n",
    "        trial.report(val_iou, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    return val_iou\n",
    "\n",
    "# Crear estudio y ejecutar la optimización\n",
    "study = optuna.create_study(direction='maximize', pruner=SuccessiveHalvingPruner())\n",
    "study.optimize(objective, n_trials=50, timeout=None)\n",
    "\n",
    "# Resultados\n",
    "print('Best trial:', study.best_trial.params)\n",
    "print('Best IoU:', study.best_trial.value)\n",
    "\n",
    "# Visualizaciones\n",
    "try:\n",
    "    # Historial de optimización\n",
    "    fig1 = vis.plot_optimization_history(study)\n",
    "    fig1.show()\n",
    "\n",
    "    # Importancia de parámetros\n",
    "    fig2 = vis.plot_param_importances(study)\n",
    "    fig2.show()\n",
    "\n",
    "    # Contorno de parámetros (si hay dos parámetros numéricos)\n",
    "    fig3 = vis.plot_contour(study)\n",
    "    fig3.show()\n",
    "\n",
    "    # Slice plot para parámetros\n",
    "    fig4 = vis.plot_slice(study)\n",
    "    fig4.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print('Error en visualizaciones:', e)\n",
    "    print('Asegúrate de tener plotly instalado: pip install plotly')\n",
    "\n",
    "print('Optuna HPO completado con selección de arquitectura y visualizaciones.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18982533",
   "metadata": {},
   "source": [
    "---\n",
    "Siguientes pasos sugeridos:\n",
    "- Ejecutar la búsqueda con `n_trials=50` y `n_epochs=5` (proxy) usando Optuna/ASHA.\n",
    "- Re-entrenar los mejores 3 candidatos con mayor resolución y más epochs.\n",
    "- Opcional: registrar en Weights & Biases para trazabilidad."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
